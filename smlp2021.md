
# SMLP 2021 

Advanced Frequentist stream

Taught by Reinhold Kliegl, Doug Bates & Phillip Alday

### Day 1, 06.09.21
1. Doug Bates (DB) presents sleepstudy.jl as full example of LMM workflow, incl. zerocorr models, caterpillar & shrinkage plots, geomdof, etc. 
2. Julius Krumbiegel shows the DataFramesMacro & Chain packages for data wrangling in Julia 
3. Reinhold Kliegl (RK) presents MixedModelsTutorial_basics.jl as workflow example on larger dataset (sport science paper)
	
	
### Day 2, 07.09.21
1. RK presents workflow in VS Code
2. RK presents sports science example from MixedModelsTutorial_basics.jl
3. DB presents participant data from /SMLP2021datasets/instructors/Dorothea_Pregla/analysis.jl
4. Q & A with RK
5. DB presents optimization with Julia v1.7 (using MLK) with SMLP2021datasets/instructors/Kyla_McConnell/speed.jl
6. DB presents Arrow (and some wrangling) from SMLP2021/notebooks/Arrow.jl

### Day 3, 08.09.21
1. Q & A with PA
2. PA presents about optimizers and fitting procedure with vizfit.jl
3. PA presents SMLP2021datasets/instructors/Sinika_Timme/analysis.jl

# Contents
- [SMLP 2021](#smlp-2021)
    + [Day 1, 06.09.21](#day-1--060921)
    + [Day 2, 07.09.21](#day-2--070921)
    + [Day 3, 08.09.21](#day-3--080921)
- [Julia basics](#julia-basics)
    + [Loading in data](#loading-in-data)
    + [Exploring data](#exploring-data)
- [Development environments](#development-environments)
  * [Pluto Notebooks](#pluto-notebooks)
    + [Pluto packages](#pluto-packages)
    + [DisplayAs & PlutoUI](#displayas---plutoui)
  * [VS Code](#vs-code)
- [Using R & Python](#using-r---python)
  * [RCall](#rcall)
  * [PyCall](#pycall)
- [LMM theory](#lmm-theory)
  * [Caterpillar plots](#caterpillar-plots)
  * [Shrinkage plots](#shrinkage-plots)
  * [Zerocorr models](#zerocorr-models)
  * [Bootstrapping](#bootstrapping)
  * [geomdof](#geomdof)
  * [Orthogonal contrasts](#orthogonal-contrasts)
  * [Correlation parameters](#correlation-parameters)
  * [R-squared](#r-squared)
  * [Contrast coding](#contrast-coding)
  * [A priori vs. post-hoc contasts](#a-priori-vs-post-hoc-contasts)
  * [Singular fits](#singular-fits)
  * [Optimizer](#optimizer)
  * [Maximal v. parsimonious](#maximal-v-parsimonious)
  * [Small grouping variables](#small-grouping-variables)
  * [Identifying overfit models](#identifying-overfit-models)
- [GLMs](#glms)
    + [Complete separation](#complete-separation)
- [Defining LMM models in Julia](#defining-lmm-models-in-julia)
    + [Grouping contrast](#grouping-contrast)
    + [Singular fits](#singular-fits-1)
    + [Model comparison](#model-comparison)
    + [Rank deficiency](#rank-deficiency)
    + [.rePCA](#repca)
    + [Differences to lme4](#differences-to-lme4)
    + [modelname.optsum()](#modelnameoptsum--)
  * [Post fit graphs](#post-fit-graphs)
  * [MixedModelsExtras](#mixedmodelsextras)
  * [effects package](#effects-package)
- [DataFramesMacro](#dataframesmacro)
  * [Chain](#chain)
    + [@aside](#-aside)
  * [Data Wrangling](#data-wrangling)
    + [select](#select)
    + [transform](#transform)
    + [transform for z-scores](#transform-for-z-scores)
    + [groupby](#groupby)
    + [groupby & combine](#groupby---combine)
    + [parent()](#parent--)
    + [first()](#first--)
    + [@transform vs transform](#-transform-vs-transform)
    + [Saving wrangled dataframes](#saving-wrangled-dataframes)
    + [recode](#recode)
    + [joins](#joins)
    + [Other wrangling code](#other-wrangling-code)
- [Julia 1.7.0 & MixedModels](#julia-170---mixedmodels)
- [Arrow data type](#arrow-data-type)
    + [Benefits of Arrow](#benefits-of-arrow)
    + [Arrow in R](#arrow-in-r)
- [Plotting in Julia](#plotting-in-julia)
    + [Ridgeplot](#ridgeplot)
- [Other Julia tips / wrangling](#other-julia-tips---wrangling)
    + [String manipulation](#string-manipulation)
    + [Variations on MixedModels fit calls](#variations-on-mixedmodels-fit-calls)
    + [Summary tables](#summary-tables)
    + [Factor levels and labels](#factor-levels-and-labels)
    + [Glossary](#glossary)
- [LME4 Tips](#lme4-tips)
    + [REML](#reml)
    + [Convergence errors in lme4](#convergence-errors-in-lme4)
- [Other resources](#other-resources)
- [Open questions](#open-questions)



# Julia basics

- Ending a call in a semicolon (;) inhibits the output
- To do an operation element-wise, i.e. on a vector, you have to broadcast with . 
```julia
	array = [1, 2, 3]
	sqrt.(array)
	array .+ 2
```
- "Symbols" are represented with a colon, ex. :subj, and are used within the MixedModels/DataFrames framework to represent column names 

### Loading in data
- Use the CSV package to read in data, here is a complex example. Note that single and double quotes mean different things, strings v. characters
- dropmissing! can either take column names or if you leave it blank, it will drop any row with a missing
- The ; is a convention to separate positional from named arguments

```julia
	dat = DataFrame(CSV.File("data/hexaff_all.csv"; comment="#", delim=';', missingstring="NA", drop=[1,2], decimal=','))
```

```julia
	dropmissing!(dat, [:FS, :timepoint, :date])
```

- There's also `skipmissing` to not drop but just skip the missing values in an array


### Exploring data
- Look at your data with describe()

```julia
	describe(dat)
```


# Development environments
## Pluto Notebooks

- Open Pluto through the Julia terminal with "using Pluto", "Pluto.run()" and typing the path in the text box.
- A Pluto cell can only contain one statement. If you want to include more than one (for example, when loading more than one package), you have to enclose the lines in 'begin' and 'end'
- To write text, enclose it in md and three "s (i.e. multi-line string preceded with md for Markdown) -- you can use Markdown syntax like **bold**, *italics* and headers with hashtags.
- Embed Julia code in Markdown with string interpolation within your markdown call with the dollar sign, i.e. `$(1+1)`
- You can output a Pluto notebook as a notebook file, or static HTML/PDF

### Pluto packages
- Pluto freezes the package versions 
- You can hover over the checkmark next to the package, and if theres an update available for a package, you can update it (and it will save a copy before)

### DisplayAs & PlutoUI
- `DisplayAs.Text()` for a purely texual output of tables/model output like youd get in the Julia REPL
- PlutoUI allows you to add a table of contents: `TableOfContents()`

## VS Code
- Install the Julia extension and (optionally) the R in Julia code highlighting extension 
- Julia markdown files (.jmd) work like R-markdown files, with chunks of text in MD and in Julia, chunks are denoted with three backticks 
- Ctrl/Cmd Enter runs one line, Alt Enter runs the logical block
- create package environment with activate . (the dot means current location) and add packages to that location (the terminal line will show that name in the line)
- you can then select the julia environment at the bottom line of VS code and it will launch Julia in that environment
- Track your project.toml in Git but not your Manifest.toml (Project has basic info whereas Manifest has more details)


# Using R & Python
## RCall
- Set up RCall: https://juliainterop.github.io/RCall.jl/stable/installation/

- Macros `@rget` and `@rput`
- JellyMe4 for lme4-like objects
- To use R in-line in Julia, use the R string type: `R" "` (or with three " for multi-line strings)


## PyCall
```julia
pymulti = @pyimport multiprocessing
pymulti.Worker (or whatever from that package)
```

- You can also do Python in strings: `py" "`
- There's also a wrapper for calling EEG package mne in Julia

# LMM theory
- Standard deviation in the LMM output is in the same scale / unit as the response variable. (Square root of the variance.) 

## Caterpillar plots
- Caterpillar plots visualize the correlation between random slopes and random intercepts
- Caterpillar plots tell you if you have a lot of variation in the subjects -> if everything is very consistent, you might not need that term
```julia
	caterpillar!(modelname, orderby=1)

	cm_m1_chrt = ranefinfo(m1)[:Cohort];
	caterpillar!(Figure(; resolution=(800,400)), cm_m1_chrt; orderby=1)

	cm_m1_schl = ranefinfo(m1)[:School];  
	caterpillar!(Figure(; resolution=(800,800)), cm_m1_schl; orderby=1)

	caterpillar(m1, :item)

```
- Note on syntax: for the ! method, you have to supply the figure (Which is then 'modified' by adding the plot). For the non mutating variant, a default figure is generated. The advantage to creating the fig ahead of time is that you can sepcify the resolution
- There is also `qqcaterpillar`, which is easier to read with more levels, because it sorts and labels along the vertical axis.

## Shrinkage plots
- Shrinkage plots: How much do the points reduce down towards zero -- if it clumps down to the origin, you might not need the random effects
- If it's going down to a horizontal line, you might need the term on the x-axis (often the intercept, though not necessarily) but not the term on the y-axis (which may be a slope)
- Participants whose data fits a line very well (337 in sleep study data) don't have as much shrinkage becuase there's not as much room to wiggle the line around, whereas other participants may be shrunk more because their individual lines can be wiggled more without losing so much fit.
- Example: Shrinkage plot is almost entirely vertical lines -- this means that the random effect on the y-axis (condition here) is not adding much value to the model. 
```julia
	shrinkage!(modelname)

	shrinkageplot!(Figure(; resolution=(800,800)), m1, :Cohort)

	shrinkageplot!(Figure(; resolution=(800,800)), m1, :School)
```
- PA: The direction of the lines gives you an idea of which components are being shrunk the most. Shrinkage is a good thing. But when a given dimension is shrunk fully to zero (so all the blue dots lie on a single line), then that speaks against including that dimension. (Collapsing to a horizontal or vertical line makes it clear which dimension is shrunk away; a diagonal line indicates that the correlation is very close to ±1, so you knowing one dimension completely defines the other)
- So if your shrinkage plot is showing everything collapsing to a line, the model may be overfit / have too many random effect terms
- If there's not much shrinkage (i.e. by participant), that the population mean is not predictive of any individual (example of Sinicas data, where each participant has a very different curve, and the shrinkage plot show very little shrinkage)
- Misspecified models may lead to "explosion" vs. shrinkage plots, i.e. anti-shrinkage plots, in general just a real mess in the shrinkage plots. PA shows example with Sinicas data where you try to fit a random effect by data measured even though only a miniority of participants were measured on more than one day. (This isn't totally confirmed as the only reason this would happen, but it's often an indicationt hat while the model is mathematically well-defined, it doesn't fit the data logically.)
- It's possible that you'd have a participant that is far away from the rest but also isn't shrunk much. This can happen if there is good evidene that this person really is that far away from the mean (in the case of a participant RE).

## Zerocorr models
- Leaving in a correlation term when its not needed (or otherwise having parameters in a model that aren't necessary) increases the risk of overfitting and adds a source of variability that is not necessary

## Bootstrapping
- Bootstrapping assumes the model is true, generates data and then checks where the values fall. So we assume that the model values are true, and generate data from these, then model these new datasets and extract the parameter values and see the range in which they fall
- Shortest coverage interval shows the most dense (smallest base) interval with 95% of the data, so you can see what range of values 
- Sleepstudy example: See how the range of the correlation term goes from -.4 to 1.0, so you can see that a zero corr model may be better.

## geomdof
- Geometric degrees of freedom: goes beyond just checking how many parameters are in a model -- sometimes removing one term may actually add more DoF / variance

## Orthogonal contrasts
- Sequential difference, sum contrast and treatment constrast coding are not orthogonal because multiple levels contain the same information (i.e. level one of a sequential difference coding takes level 2 compared to level 1, whereas the second level takes level 3 compared to level 2)
- Disadvantages of non-orthogonal contrasts: they are correlated in how they're constructed, so it's sometimes not possible to tell which factor level the variance is coming from -- this variance must then be discarded
- Visual aid of a venn diagramm: orthogonal contrasts both overlap with the DV -- they explain separatable parts of the variance; non-orthogonal contrasts share variance with the DV but also with each other and this space where all three overlap (variance in the DV plus variance in more than one level of the contrasts) must be discarded. This discarding leads to a loss in statistical power.
- The more levels of the predictor you have, i.e. the more indicator variables that come from your contrast coding, the more of these overlapping areas of variance you have that have to be discarded and thus the more power lost.
- The variance described by orthogonal contrasts (by the indicator variables that represent the levels of the orthogonal contrasts) sums up to the R2, the variance described by the model. 

## Correlation parameters
- Correlations between random effects show not "does a kid who runs fast also jump high", that would be at the level of the data. 
- With non-orthogonal coding schemes, watch for if the levels/indicator variables are (negatively) artefactually correlated, because the same underlying levels are in multiple comparisons/levels (ex of star run -- either it's closer to endurance, in which case it will negatively correlate with the difference to sprint speed, or vice versa). 
- ... (still need more info here)

## R-squared 
- Trying to extend the R-squared to a mixed model is not possible, since it's based on the Pearsons correlation coefficient, which has no concept of variance by random factors
- R-squared is often viewed as "variation explained" but it's unclear what that would mean in a mixed model
- Alternatives: Fitted vs. observed plot, looking at what your model is and is not capturing 
- Standardized effect sizes are not necessary or useful in this context
- There exist packages for R2 for LMMs but they do not behave how you would expect / it doesnt have the same implications

## Contrast coding
- Contrast coding options: https://juliastats.org/StatsModels.jl/stable/contrasts/
- Preprint by Alday & Brehm "A decade of mixed models: It’s past time to set your contrasts"

## A priori vs. post-hoc contasts
- ?

## Singular fits 
- Ellipse collaspes into a line (like a wire is 3d but you consider it to be 1d for all practical purposes)
- More complexity in model specification than justified by your data 
- There may be variation in subjects/items/random effects, but it's so minor that it's not really relevant to distinguish it from the noise (indistinguishable from the residual variation)
- PA: For mixed models, its not just the number of observations, but also the number of participants and the number of items -> even if you have a lot of measurements, if you dont have many levels of the random effects then it gets difficult to estimate them
- PA: Having more trials per participants does help in some way, because it helps you define that participant well, but if you have few participants, it's still difficult -- so there's not a clear answer / perfect rule on which to increase first (items or participant), you should try to get as many people and items as possible but possible is ofc subjective. "It's not always possible to make the inferences we want based on the data we have, and just because we have spent time/money getting the data doesn't mean that we can make the inferences we want to make, and statistics won't save you there." So sometimes we have to accept uncertainty.
- At least one of the random effect terms' SD has gone to 0, or one of the correlation terms has gone to +1 or -1 (so they perfectly predict each other according to the model), aka at least dimension is redundant
- Example of a very strong correlation within subject of starting high in assessment leading to a small increase in assessment at a later time point vs. starting low correlating with a strong increase at the later time point (ex of children's development
- So the variance can be described in less dimensions than you've given

## Optimizer
- BobyQA is the default in MixedModels.jl and lme4, and works better than the others, see vizfit.jl for a visualization (but the visualization is a singular fit, you'll see the theta estimates / random effects parameters collapse to 0 in the second panel with green/orange lines)
- How many iterations are too many? This could become relevant when doing simulations, for example. You often reach a close guess at the estimates around 300 iterations, but you only know for sure if that's true / if you're actually close if you continue to run. 
- There is also scale sensitivity: with large datasets, you're more able to detect when you're "off just a little bit"
- In Julia, each iteration takes far less time, so we can typically let it run and not have to set a maximum number of iterations
- There is the option of a maximum amount of time or max amount of iterations before just stopping the fitting process -- not generally a super great idea but it's available of option
- Premature stopping risks not having an ideal solution -- might be fine for power analysis but not other things
- Other visualization in vizfit.jl shows the SDs by random effects which vary between 1 and 0 where 0 is the residual SD (artificial scale Cholesky.. ??), and the rhos that show the correlation terms between -1 and 1. Basically it shows that many parameters condense to 0, other than the random effect by item and subject, which are the most important

## Maximal v. parsimonious
- Modeling decisions have to be made, and you should be able to justify your decisions based on your data

## Small grouping variables
- Having a grouping variable / random effect that is very small, i.e. 5 levels, is not great because the error of a mean on 5 things is quite large, the error on the variance of 5 things is even larger.
- https://www.muscardinus.be/2018/09/number-random-effect-levels/
- If you have a small grouping variable but some of those sources of variance are taken care of in fixed effects, then you might be able to get away with that, for example if you have less participants but you account for their age and other important factors as fixed effects.

## Identifying overfit models
- Corelation parameter goes to 1 or -1
- SD goes to 0
- Residual is 0 or very tiny
- The deviance is negative in a likelihoodtest (guess this is pretty rare but it is weird)
- AIC is negative 

# GLMs

### Complete separation
- Complete separation = the two response categories are deterministically separated (so there is some combination of predictors that results in always 1 or always 0 responses). Since there is no stochastic component, it's impossible to estimate the slope of the line connecting the 0 and the 1 resonses.
- https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#penalizationhandling-complete-separation

# Defining LMM models in Julia

### Grouping contrast
- You can assign a column as a Grouping factor (in your contrasts Dict), which will speed up the computation because it tells the model to ignore that column when trying to create contrasts. This is useful for large datasets where there are a lot of levels of the grouping variables (i.e. 10,000 individuals)
- Z-scoring a predictor within a grouping variable:
```julia
	select!(groupby(dat,  :Test), :, :score => zscore => :zScore);
```
- It becomes important to set a random effect as a Grouping contrast if it is read in as a numeric (like if you have numbers for participant ID).

### Singular fits
- You can quickly check for overparametrized/degenerate models with `issingular()`
```julia
	issingular(modelname)
```

### Model comparison
- Make a manual table that includes AIC, AICc (not sure what that is!), and BIC. BIC is the most conservative.
```julia
	mods = [m_ovi, m_zcp, m_cpx];
	gof_summary = DataFrame(dof=dof.(mods), deviance=deviance.(mods),
              AIC = aic.(mods), AICc = aicc.(mods), BIC = bic.(mods))
```
- Or use the MixedModel likelihood ratio test
```julia
	MixedModels.likelihoodratiotest(m_zcpCohort_2, m_zcpCohort, m_cpxCohort)
```

### Rank deficiency 
- https://juliastats.org/MixedModels.jl/stable/rankdeficiency/

### .rePCA
- Show cumulative variance explained by the random effects terms
- If you count at what point the variance reaches or gets very close to 1.0, then that is very roughly the number of random terms you need 

### Differences to lme4
- Define your formula using the @formula macro
- Interactions are denoted with & (instead of the colon)

### modelname.optsum()
- Info about the fit, -1 means go forever (i.e. number of iterations, time to fit, etc.)
- FTOL_REACHED is what you want, this means that the optimization reached a solution point within its tolerance, you wouldn't want to see something like forced stop

You could also set a max number of iterations or time in s, or change the optimizer
```julia
	modelname.optsum.maxfeval = 300
	modelname.optsum.maxtime = 10 
	modelname.optsum.optimizer = :LN_COBYLA 
```
You can use any optimizer from the NLTOKs(?) package.

## Post fit graphs
- Plot observed v. fit with base Makie
```julia
	scatter(fitted(modelname), response(modelname))
```
- Plot residuals v. fitted
```julia	
	scatter(residuals(modelname), fitted(modelname))
```
- qqplot with line: diverging from the line indicates heavy tails, flatlining at the end indicated bounded data
```julia	
	qqnorm(modelname)
```
- Cool new plots in MixedModelsMakie where you can do a ridgeplot of bootstrap estimates of coefficients(?) or randeff(?) -- check & the line underneath is the shortest coverage interval

## MixedModelsExtras
- Extra functions that aren't really recommended but are available

## effects package
- Effects are invariant to contrast codings because they come from the predictions, which is what makes it good for understanding your contrasts



# DataFramesMacro

-  presentation by Julius Krumbiegel, contributor to Chain and DataFramesMacro


## Chain
- You can use the inline pipe |> when the item before can be taken as the first argument and you don't need additional arguments
- To do that, you could make an anonymous function as a step in the pipeline
```julia
	x -> CSV.write("test.csv", x)
```
- The chain package fixes this problem


### @aside
- Does an operation within a chain but does not keep sending it along the pipeline, i.e. for writing to disk in the middle of a pipeline


## Data Wrangling
- transform (= mutate)
- select (= select)
- groupby (= group_by)
- combine (= summarize)
- subset (= filter)


### select
- Works similar to select in tidyverse
- Can also use Not() as a helper function
```julia
	select(dat, Not([:FS, :HR])
```

### transform

- transform takes as first argument a dataframe, then a column (symbol), then a rowwise operator (like an ifelse) and then an output (new column)
- Teritary operator is like an ifelse (the following prints yes if 3 is greater than 1 and no if it is not):
```julia
	3 > 1 ? "yes" : "no"
```
- The rowwise operator should be an anonymous function (in the example below, "x" could be replaced by any label, i.e. "sex" or "row_value")

```julia
transform(df, :Sex =>
	ByRow(x -> x == "female" ? "girl" : "boy") =>
	:type);
```

The above will copy the df and make a new column called "Type" 

Below is the short format, via the macro
```julia
@transform(df, :type = :Sex == "female" ? "girl" : "boy");

transform(df, :age => (col -> col .+ 1) => :ageplus);

@transform(df, :age + 1);

@transform(df, @c :age .- mean(:age));
```

### transform for z-scores
@c inside of the @transform macro means that its not rowwise (column flag c)
```julia
	@transform!(groupby(Score, :Test), :zScore = @c zscore(:score))
```

### groupby
```julia
summary_table = @chain df begin
	@transform(:type = :Sex == "female" ? "girl" : "boy")
	@groupby(:half = :zScore > 0 ? "upper" : "lower", :type)
	combine(nrow => :n)
end;
```

### groupby & combine
- Like group_by and summarize in R 
- i.e. The following code will group by child and return the number of rows per child
```julia
	combine(groupby(nobsChild, :n), nrow)
```

### parent()
- Similar to ungroup in R-tidyverse
- If you have a grouped dataframe, it takes away that grouping

### first()
- "Goes into" a grouped dataframe and returns only those rows that are in the first grouping, i.e. returns a new table of just those rows in the first grouping

### @transform vs transform
- i.e. the advantages of DataFrameMacros
- (roughly) the transform macro automatically does operations rowwise, whereas if you use transform you have to use ByRow and an anonymous function or broadcast function

### Saving wrangled dataframes
- `@transform!` etc. for in-place steps, you'd have to do it in each step (I think)
- you can also do a non-mutating first step so that you have a safe copy, then continuing by changing in place 

### recode
```julia
	recode!(df, "Run" => "Endurance", "Star_r" => "Coordination")
```
Also look up: levels() for releveling


### joins
The `disallowmissing!` will fail if missing values were created, so it works like a flag.
```julia
	df1 = disallowmissing!(leftjoin(Score, Child1; on=:Child))
```

### Other wrangling code 

This one takes a summary table (nobsChild) of number of obs by participant and joins it back onto the main dataframe, so that each row shows the number of observations, then groups that dataframe by the number of observations
```julia
	gdf = groupby(disallowmissing!(leftjoin(Child, nobsChild; on=:Child)), :n)
```	
This one takes the first grouping (1 observation? Maybe? Depending on how it was done) and returns the gender distribution by number of rows
```julia
	combine(groupby(first(gdf), :Sex), nrow => :n)
```

# Julia 1.7.0 & MixedModels
- Julia v1.6 used OpenBLAS (Basic Linear Algebra Subroutines), but Intel has optimized linear algebra processes called MKL (Math Kernel Library), which works especially well on Intel CPUs
- Switching to Julia v1.7 saves some time fitting LMMs on Intel processors
- But, adding `using MKL` speeds up the fit significantly, though it can also change the optimum slightly (because of floating point operations in computation). This can even make it twice as fast.
- See example: https://github.com/RePsychLing/SMLP2021datasets/blob/main/instructors/Kyla_McConnell/speed.md


# Arrow data type
### Benefits of Arrow
- Language independent columnar memory format that is language independent (though called feather in R and Python)
- Arrow is native to Julia 
- CategoricalArrays doesn't work well with Pluto, so if you are having issues displaying data in Pluto, try to load in the data, save it in Arrow format, then read that Arrow-formatted data back in. 
- Example below, the path could be any, dfrm is the variable containing the R-data from `fn = Downloads.download("https://osf.io/xawdb/download?version=2");` and `dfrm = rcopy(R"readRDS($fn)")`
```julia
	tbl = Arrow.Table(Arrow.write("./data/fggk21.arrow", dfrm; compress=:zstd))
```
- Filesizes will be smaller / quicker to work with because it doesn't save some repeated information (?)
- Read in an arrow file with `DataFrame(Arrow.Table("./data/fggk21_Score.arrow"))`
- Because Arrow reads in data as a column, it can save the column type (incl. e.g. factor vs. string)
- However, it is not human-readab

### Arrow in R
```julia
	library("arrow")
	fggk21 <- read_feather("./data/fggk21.arrow")
```

# Plotting in Julia

### Ridgeplot
Not sure if this is the full code needed here or what data wrangling you have to do in advance to get grouped ridges / densities
```julia
	ridgeplot(parent(gdf), :age, :n)
```

# Other Julia tips / wrangling

### String manipulation
- Change numeric subject IDs to format (S00004, etc.): Starting with S, left-padding 0s of the number of digits of the maximum number. 
```julia
	df.subj = string.('S', lpad.(df.subj, ndigits(maximum(df.subj)), '0'));
```

### Variations on MixedModels fit calls
- You can filter subsets of data within the MixedModel fit call: 
```julia
	m1 = fit(MixedModel, formula,
	filter(:region => ==("2"), df);
	contrasts = cntrsts))
```

### Summary tables
- This could be rewritten with Chain and MixedModelMacros, but the idea is (1) cut the age column into 8 groups and select only the necessary columns, (2) group by age, sex and test, (3) take the mean of the z-score column and the age column and (4) return this summary table.
```julia
	df = groupby(  
	 combine(
		groupby(
			select(dat,
				:age => (x -> cut(x, 8)) => :Age,
				:Sex,
				:Test,
				:zScore,
				:age
			),
			[:Age, :Sex, :Test]),
		:zScore => mean => :zScore,
		:age => mean => :ageM
		),
	:Test
	);
```

### Factor levels and labels
```julia
	recode!(dat.Test,
		"Endurance"  => "Run",
		"Coordination" => "Star_r",
	    "Speed" => "S20_r",
		"PowerLOW" => "SLJ",
		"PowerUP" => "BPT")

	levels!(dat.Sex,  ["Girls", "Boys"])
```

### Graphing w/ Makie
- "Algebra of graphics"
- https://makie.juliaplots.org/stable/tutorials/
- https://makie.juliaplots.org/stable/examples/plotting_functions/
- Beautiful Makie: https://lazarusa.github.io/BeautifulMakie/

- MixedModelsMakie: https://github.com/palday/MixedModelsMakie.jl

### Glossary
Available in MixedModelsTutorial_Basic (bottom of file)

# LME4 Tips

### REML
- Pretty much always use REML = FALSE
- Likelihood ratio tests rely on using -the- likelihood not -a- likelihood ratio
- DB: REML tries to adjust the math to produce something that was thought to be better but really isn't
- REML = FALSE is default in MixedModels.jl (I think)

### Convergence errors in lme4
- For singular fits, try adding "control = lmerControl(calc.derivs = FALSE)"
- After fitting, lme4 runs post-hoc convergence tests, some of which are not necessary or fail on maximal models (thats why you can set calc.derivs to false) -> maximal models are on the boundary (not in the middle of the "space") so this will fail, these models are singular
- Models that truly fail to fit, not just fail one of these post-hoc test, often mean that your model does not align with your data 
- ??? Maximal models are singular 


# Other resources
- Schad et al. "How to Capitalize on a priori contrasts in linear (mixed) models": https://doi.org/10.1016/j.jml.2019.104038
- Wagenmakers et al. Various papers on confirmatory v. exploratory analysis, incl: https://doi.org/10.1177/1745691612463078
- Using a variable as both a random and a fixed effect: https://www.muscardinus.be/2017/08/fixed-and-random/
- Kliegl et al. interpretting correlation parameters of random effects: https://doi.org/10.3389/fpsyg.2010.00238 (hope this is the right paper)
- Computing effect sizes for mixed models: https://afex.singmann.science/forums/topic/compute-effect-sizes-for-mixed-objects#post-295
- Required number of levels for grouping factors: https://www.muscardinus.be/2018/09/number-random-effect-levels/
- Non-parametric bootstrap: http://www.sumsar.net/blog/2015/04/the-non-parametric-bootstrap-as-a-bayesian-model/



# Open questions 
- How do you interpret correlation of random effects? In general, what does it mean if you have a strong correlation between random effects. And if you bootstrap to find the coverage interval, when would this be significant and when would the range be too wide (i.e. if the range is (.2 - .5) vs. (.1 - .9). 
	- RKs paper: https://doi.org/10.3389/fpsyg.2010.00238

- How do you interpret caterpillar and shrinkage plots theoretically? What are you looking for to determine whether a term is adding to the fit? And what conclusions can you draw about your model from them?

- How does graphing in Julia / MixedModelsMakie work?

